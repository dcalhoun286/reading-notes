# Ethics in Tech

**Assignment**: Review at least one article from both "Ethics in the workplace" and "Ethics in Technology" sections below and write how each of them relates to ethics in technology. Do you agree or disagree with these articles? What stuck out to you specifically from each article?

## Preparation Materials

### Code of Ethics

Skim:

1. [Code of Ethics](https://www.acm.org/code-of-ethics)
1. [Software Engineering Code of Ethics](https://ethics.acm.org/code-of-ethics/software-engineering-code/)

### Ethics in the workplace

1. [The code I'm still ashamed of](https://medium.freecodecamp.org/the-code-im-still-ashamed-of-e4c021dff55e)
1. [Project Dragonfly, Google's censored search engine](https://www.vox.com/2018/8/17/17704526/google-dragonfly-censored-search-engine-china)
1. [Amazon workers demand Jeff Bezos cancel "Recognition" software](https://gizmodo.com/amazon-workers-demand-jeff-bezos-cancel-face-recognitio-1827037509)
1. [Google and AI](https://gizmodo.com/in-reversal-google-says-its-ai-will-not-be-used-for-we-1826649327)
1. [Microsoft Employees demand end of ICE contract](https://www.nytimes.com/2018/06/19/technology/tech-companies-immigration-border.html)
1. [Microsoft and the DoD](https://www.businessinsider.com/microsoft-employees-protest-contract-us-army-hololens-2019-2)

### Ethics in Technology

1. [Self Driving Car Ethics](https://www.freep.com/story/money/cars/2017/11/21/self-driving-cars-ethics/804805001/)
1. [Ethical dilemma of self driving cars](https://www.theglobeandmail.com/globe-drive/culture/technology/the-ethical-dilemmas-of-self-drivingcars/article37803470/)
1. [Cyber-Security of self driving cars](https://phys.org/news/2017-02-cybersecurity-self-driving-cars.html)
1. [Big Data is our Civil Rights issue](http://solveforinteresting.com/big-data-is-our-generations-civil-rights-issue-and-we-dont-know-it/)
1. [Will democracy survive big data and AI?](https://www.scientificamerican.com/article/will-democracy-survive-big-data-and-artificial-intelligence/)

### Tech Company Principles

1. [Microsoft AI Principles](https://www.microsoft.com/en-us/AI/our-approach-to-ai)
1. [Ethical OS Toolkit](https://ethicalos.org/)
1. [Google AI Principles](https://www.blog.google/technology/ai/ai-principles/)

## Responses

### "The code I'm still ashamed of" - Bill Sourour

What stuck out to me in this article -- and one of the parts of this story that caught me most off-guard, was when the PM approached the author with a concern that something was amiss with the quiz he quoted. When he clarified that the design of the quiz was intentional per the technical requirements (even if to the detriment of a potential patient), the PM seemed to conclude this was a non-issue. Perhaps I was expecting the PM to guide the author in having a discussion with the client about how potentially harmful building a website per the technical requirements would be and that they weren't comfortable carrying out the requirements. Even if the company cared much more about bottom line than ethics, the technical requirements as mentioned in the article actually _don't_ seem like they follow the letter and spirit of Canadian laws that determine how pharmaceutical companies can advertise, which would potentially include the development team liability. The author said that no laws were violated, but I'm not sure I agree. In any case, the website was misleading in that it presented itself as a general information site with the deliberate intent to advertize a particular drug through its rigged quiz, and someone unfortunately took her own life because of it. There are many other ethical violations that stand out to me from this article, but one of the biggest takeaways I see from it is to recognize that just because you "can" do something, it doesn't mean you should: we have just as much responsibility to evaluate the potential negative consequences of creating software as our client and act accordingly, even if it is in conflict with our client's wishes.

### "Morality, ethics of a self-driving car: Who decides who lives, dies?" - Todd Spangler

I fully accept that the following opinion might someday be proven wrong, but it does not sound to me like we are currently close to having the technology for which ethics could justify completely self-driving vehicles to the point that it becomes mainstream. Patrick Lin, director of the Ethics and Emerging Sciences Group at California Polytechnic State University, was quoted something that really resonated with me: "[some automakers] simply deny that ethics is a real problem, without realizing that they're making ethical judgment calls all the time [in their development]". I agree with many of those who expressed the opinion that the goal should not be to come up with self-driving cars so smart that no accidents happen ever, and that at least some of the theoretical scenarios are contrived. Furthermore, I see the potential value in developing such technology because the vast majority of the thousands of deaths each year due to automobile accidents are because of human error. What gives me pause is something else the article also mentions: this could put thousands of people out of work and can therefore destroy huge sectors of the transportation industry, those most significantly impacted more than likely being groups of people who are already of a socioeconomically vulnerable status. I don't think there is enough emphasis on _who_ is paying the cost versus _how many_. It seems more sensible at least for now to continue developing and improving upon already existing technology, [Driver Assistance Technologies](https://www.nhtsa.gov/equipment/driver-assistance-technologies).

## [Back to home](https://dcalhoun286.github.io/reading-notes/)
